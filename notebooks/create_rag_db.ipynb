{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "import sqlparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_repo_root_path():\n",
    "    import os\n",
    "    import sys\n",
    "    repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    if repo_root not in sys.path:\n",
    "        sys.path.append(repo_root)\n",
    "        \n",
    "add_repo_root_path()\n",
    "from src import generate_knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "#pd.set_option('display.width', None)\n",
    "#pd.set_option('display.max_colwidth', 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaffle-shop\n"
     ]
    }
   ],
   "source": [
    "local_dbt_repo = ''\n",
    "online_dbt_repo = 'https://github.com/dbt-labs/jaffle-shop'\n",
    "\n",
    "# Use local repo?\n",
    "if False:\n",
    "    repo_path = local_dbt_repo\n",
    "else:\n",
    "    repo_path = online_dbt_repo\n",
    "\n",
    "is_online = generate_knowledge.is_online_repo(repo_path)\n",
    "_, repo_name = generate_knowledge.extract_owner_and_repo(repo_path)\n",
    "print(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>extension</th>\n",
       "      <th>sql_code</th>\n",
       "      <th>config</th>\n",
       "      <th>materialized</th>\n",
       "      <th>is_snapshot</th>\n",
       "      <th>has_jinja_code</th>\n",
       "      <th>model_category</th>\n",
       "      <th>vertical</th>\n",
       "      <th>yml_code</th>\n",
       "      <th>tests</th>\n",
       "      <th>has_tests</th>\n",
       "      <th>sql_ids</th>\n",
       "      <th>has_select_all_in_last_select</th>\n",
       "      <th>has_group_by</th>\n",
       "      <th>primary_key</th>\n",
       "      <th>filters</th>\n",
       "      <th>is_filtered</th>\n",
       "      <th>macros</th>\n",
       "      <th>has_macros</th>\n",
       "      <th>parent_models</th>\n",
       "      <th>is_source_model</th>\n",
       "      <th>source</th>\n",
       "      <th>children_models</th>\n",
       "      <th>is_end_model</th>\n",
       "      <th>model_description</th>\n",
       "      <th>jinja_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models/marts/products.sql</td>\n",
       "      <td>products.sql</td>\n",
       "      <td>.sql</td>\n",
       "      <td>WITH products AS\\n  (SELECT *\\n   FROM {{ ref(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>other</td>\n",
       "      <td>products</td>\n",
       "      <td>{'semantic_models': [{'name': 'products', 'des...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['stg_products']</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>Retrieves all product records from the 'stg_pr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/staging/stg_products.sql</td>\n",
       "      <td>stg_products.sql</td>\n",
       "      <td>.sql</td>\n",
       "      <td>WITH SOURCE AS\\n  (SELECT *\\n   FROM {{ source...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>stg</td>\n",
       "      <td>products</td>\n",
       "      <td>{'models': [{'name': 'stg_products', 'descript...</td>\n",
       "      <td>{'columns': {'product_id': ['not_null', 'uniqu...</td>\n",
       "      <td>True</td>\n",
       "      <td>['product_id']</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>product_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['cents_to_dollars']</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>['ecom.raw_products']</td>\n",
       "      <td>['order_items', 'products']</td>\n",
       "      <td>False</td>\n",
       "      <td>Retrieves product data from the 'raw_products'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>models/marts/locations.sql</td>\n",
       "      <td>locations.sql</td>\n",
       "      <td>.sql</td>\n",
       "      <td>WITH locations AS\\n  (SELECT *\\n   FROM {{ ref...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>other</td>\n",
       "      <td>locations</td>\n",
       "      <td>{'semantic_models': [{'name': 'locations', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['stg_locations']</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>Retrieves all location records from the 'stg_l...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               path              name extension  \\\n",
       "11        models/marts/products.sql      products.sql      .sql   \n",
       "4   models/staging/stg_products.sql  stg_products.sql      .sql   \n",
       "7        models/marts/locations.sql     locations.sql      .sql   \n",
       "\n",
       "                                             sql_code config materialized  \\\n",
       "11  WITH products AS\\n  (SELECT *\\n   FROM {{ ref(...    NaN          NaN   \n",
       "4   WITH SOURCE AS\\n  (SELECT *\\n   FROM {{ source...    NaN          NaN   \n",
       "7   WITH locations AS\\n  (SELECT *\\n   FROM {{ ref...    NaN          NaN   \n",
       "\n",
       "    is_snapshot  has_jinja_code model_category   vertical  \\\n",
       "11        False           False          other   products   \n",
       "4         False           False            stg   products   \n",
       "7         False           False          other  locations   \n",
       "\n",
       "                                             yml_code  \\\n",
       "11  {'semantic_models': [{'name': 'products', 'des...   \n",
       "4   {'models': [{'name': 'stg_products', 'descript...   \n",
       "7   {'semantic_models': [{'name': 'locations', 'de...   \n",
       "\n",
       "                                                tests  has_tests  \\\n",
       "11                                                NaN      False   \n",
       "4   {'columns': {'product_id': ['not_null', 'uniqu...       True   \n",
       "7                                                 NaN      False   \n",
       "\n",
       "           sql_ids  has_select_all_in_last_select  has_group_by primary_key  \\\n",
       "11             NaN                           True         False         NaN   \n",
       "4   ['product_id']                           True         False  product_id   \n",
       "7              NaN                           True         False         NaN   \n",
       "\n",
       "   filters  is_filtered                macros  has_macros      parent_models  \\\n",
       "11     NaN        False                   NaN       False   ['stg_products']   \n",
       "4      NaN        False  ['cents_to_dollars']        True                 []   \n",
       "7      NaN        False                   NaN       False  ['stg_locations']   \n",
       "\n",
       "    is_source_model                 source              children_models  \\\n",
       "11            False                    NaN                           []   \n",
       "4              True  ['ecom.raw_products']  ['order_items', 'products']   \n",
       "7             False                    NaN                           []   \n",
       "\n",
       "    is_end_model                                  model_description  \\\n",
       "11          True  Retrieves all product records from the 'stg_pr...   \n",
       "4          False  Retrieves product data from the 'raw_products'...   \n",
       "7           True  Retrieves all location records from the 'stg_l...   \n",
       "\n",
       "    jinja_description  \n",
       "11                NaN  \n",
       "4                 NaN  \n",
       "7                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>extension</th>\n",
       "      <th>code</th>\n",
       "      <th>is_seed</th>\n",
       "      <th>is_macro</th>\n",
       "      <th>is_test</th>\n",
       "      <th>packages</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>package-lock.yml</td>\n",
       "      <td>package-lock.yml</td>\n",
       "      <td>.yml</td>\n",
       "      <td>packages:\\n- package: dbt-labs/dbt_utils\\n  ve...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jaffle-data/raw_customers.csv</td>\n",
       "      <td>raw_customers.csv</td>\n",
       "      <td>.csv</td>\n",
       "      <td>id          ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jaffle-data/raw_supplies.csv</td>\n",
       "      <td>raw_supplies.csv</td>\n",
       "      <td>.csv</td>\n",
       "      <td>id                        name  cost  per...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             path               name extension  \\\n",
       "2                package-lock.yml   package-lock.yml      .yml   \n",
       "6   jaffle-data/raw_customers.csv  raw_customers.csv      .csv   \n",
       "11   jaffle-data/raw_supplies.csv   raw_supplies.csv      .csv   \n",
       "\n",
       "                                                 code  is_seed  is_macro  \\\n",
       "2   packages:\\n- package: dbt-labs/dbt_utils\\n  ve...    False     False   \n",
       "6                                     id          ...    False     False   \n",
       "11       id                        name  cost  per...    False     False   \n",
       "\n",
       "    is_test packages description  \n",
       "2     False      NaN         NaN  \n",
       "6     False      NaN         NaN  \n",
       "11    False      NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbt_models_df = pd.read_csv('../data/dbt_models_' + repo_name + '.csv')\n",
    "dbt_project_df = pd.read_csv('../data/dbt_project_' + repo_name + '.csv')\n",
    "display(dbt_models_df.sample(3))\n",
    "display(dbt_project_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dbt_models_and_project_dfs(dbt_models_df, dbt_project_df):\n",
    "    dbt_models_df['knowledge_type'] = 'models'\n",
    "    dbt_project_df['knowledge_type'] = 'project'\n",
    "\n",
    "    dbt_models_df.rename(columns = {'sql_code':'code'}, inplace = True)\n",
    "\n",
    "    all_columns = set(dbt_models_df.columns).union(set(dbt_project_df.columns))\n",
    "\n",
    "    for col in all_columns:\n",
    "        if col not in dbt_models_df:\n",
    "            dbt_models_df[col] = None\n",
    "        if col not in dbt_project_df:\n",
    "            dbt_project_df[col] = None\n",
    "\n",
    "    merged_df = pd.concat([dbt_models_df, dbt_project_df], ignore_index=True)\n",
    "    columns_order = ['knowledge_type'] + [col for col in merged_df.columns if col != 'knowledge_type']\n",
    "    return merged_df[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbt_repo_knowledge_df = merge_dbt_models_and_project_dfs(dbt_models_df, dbt_project_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings and Documents db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_contextual_fields(row):\n",
    "    combined = f\"\"\"        \n",
    "        Code:\n",
    "        {row['code'] if pd.notna(row['code']) else 'N/A'}\n",
    "\n",
    "        Primary Key:\n",
    "        {row['primary_key'] if pd.notna(row['primary_key']) else 'N/A'}\n",
    "\n",
    "        IDS:\n",
    "        {row['sql_ids'] if pd.notna(row['sql_ids']) else 'N/A'}\n",
    "\n",
    "        Columns used to Filter the model throuhg JOINS, HAVING, WHERE...:\n",
    "        {row['filters'] if pd.notna(row['filters']) else 'N/A'}\n",
    "\n",
    "        Tests:\n",
    "        {row['tests'] if pd.notna(row['tests']) else 'N/A'}\n",
    "\n",
    "        YML Code:\n",
    "        {row['yml_code'] if pd.notna(row['yml_code']) else 'N/A'}\n",
    "\n",
    "        Description for project files:\n",
    "        {row['description'] if pd.notna(row['description']) else 'N/A'}\n",
    "\n",
    "        dbt Model description:\n",
    "        {row['model_description'] if pd.notna(row['model_description']) else 'N/A'}\n",
    "\n",
    "        Jinja inside the dbt model description:\n",
    "        {row['jinja_description'] if pd.notna(row['jinja_description']) else 'N/A'}\n",
    "    \"\"\"\n",
    "    return combined.strip()\n",
    "\n",
    "dbt_repo_knowledge_df['contextual_info'] = dbt_repo_knowledge_df.apply(combine_contextual_fields, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_knowledge.add_repo_root_path()\n",
    "import openai_setup\n",
    "\n",
    "OPENAI_API_KEY = openai_setup.conf['key']\n",
    "OPENAI_PROJECT = openai_setup.conf['project']\n",
    "OPENAI_ORGANIZATION = openai_setup.conf['organization']\n",
    "DEFAULT_LLM_MODEL = \"gpt-4o-mini\"\n",
    "CHROMADB_DIRECTORY = '../chromadb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = dbt_repo_knowledge_df.apply(\n",
    "    lambda row: Document(\n",
    "        page_content=row[\"contextual_info\"],\n",
    "        metadata={\n",
    "            \"knowledge_type\": row[\"knowledge_type\"],\n",
    "            \"name\": row[\"name\"],\n",
    "            \"path\": row[\"path\"],\n",
    "            \"source\": row[\"source\"],\n",
    "            \"parents\": row[\"parent_models\"],\n",
    "            \"children\": row[\"children_models\"],\n",
    "            \"config\": row[\"config\"],\n",
    "            \"materialized\": row[\"materialized\"],\n",
    "            \"is_snapshot\": row[\"is_snapshot\"],\n",
    "            \"model_category\": row[\"model_category\"],\n",
    "            \"vertical\": row[\"vertical\"],\n",
    "            \"has_tests\": row[\"has_tests\"],\n",
    "            \"has_select_all_in_last_select\": row[\"has_select_all_in_last_select\"],\n",
    "            \"has_group_by\": row[\"has_group_by\"],\n",
    "            \"is_filtered\": row[\"is_filtered\"],\n",
    "            \"is_source_model\": row[\"is_source_model\"],\n",
    "            \"is_seed\": row[\"is_seed\"],\n",
    "            \"is_end_model\": row[\"is_end_model\"],\n",
    "            \"is_macro\": row[\"is_macro\"],\n",
    "            \"is_test\": row[\"is_test\"],\n",
    "            \"macros\": row[\"macros\"],\n",
    "            \"packages\": row[\"packages\"]\n",
    "        }\n",
    "    ), axis=1\n",
    ").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowledge_type</th>\n",
       "      <th>path</th>\n",
       "      <th>name</th>\n",
       "      <th>extension</th>\n",
       "      <th>code</th>\n",
       "      <th>config</th>\n",
       "      <th>materialized</th>\n",
       "      <th>is_snapshot</th>\n",
       "      <th>has_jinja_code</th>\n",
       "      <th>model_category</th>\n",
       "      <th>vertical</th>\n",
       "      <th>yml_code</th>\n",
       "      <th>tests</th>\n",
       "      <th>has_tests</th>\n",
       "      <th>sql_ids</th>\n",
       "      <th>has_select_all_in_last_select</th>\n",
       "      <th>has_group_by</th>\n",
       "      <th>primary_key</th>\n",
       "      <th>filters</th>\n",
       "      <th>is_filtered</th>\n",
       "      <th>macros</th>\n",
       "      <th>has_macros</th>\n",
       "      <th>parent_models</th>\n",
       "      <th>is_source_model</th>\n",
       "      <th>source</th>\n",
       "      <th>children_models</th>\n",
       "      <th>is_end_model</th>\n",
       "      <th>model_description</th>\n",
       "      <th>jinja_description</th>\n",
       "      <th>packages</th>\n",
       "      <th>is_macro</th>\n",
       "      <th>is_seed</th>\n",
       "      <th>description</th>\n",
       "      <th>is_test</th>\n",
       "      <th>contextual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models</td>\n",
       "      <td>models/marts/products.sql</td>\n",
       "      <td>products.sql</td>\n",
       "      <td>.sql</td>\n",
       "      <td>WITH products AS\\n  (SELECT *\\n   FROM {{ ref(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>other</td>\n",
       "      <td>products</td>\n",
       "      <td>{'semantic_models': [{'name': 'products', 'des...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['stg_products']</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>Retrieves all product records from the 'stg_pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Code:\\n        WITH products AS\\n  (SELECT *\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models</td>\n",
       "      <td>models/staging/stg_orders.sql</td>\n",
       "      <td>stg_orders.sql</td>\n",
       "      <td>.sql</td>\n",
       "      <td>WITH SOURCE AS\\n  (SELECT *\\n   FROM {{ source...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>stg</td>\n",
       "      <td>orders</td>\n",
       "      <td>{'models': [{'name': 'stg_orders', 'descriptio...</td>\n",
       "      <td>{'columns': {'order_id': ['not_null', 'unique'...</td>\n",
       "      <td>True</td>\n",
       "      <td>['location_id', 'store_id', 'customer_id', 'or...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>order_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['cents_to_dollars', 'dbt.date_trunc']</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>['ecom.raw_orders']</td>\n",
       "      <td>['order_items', 'orders']</td>\n",
       "      <td>False</td>\n",
       "      <td>Retrieves order data from the 'ecom.raw_orders...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Code:\\n        WITH SOURCE AS\\n  (SELECT *\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>models</td>\n",
       "      <td>models/marts/locations.sql</td>\n",
       "      <td>locations.sql</td>\n",
       "      <td>.sql</td>\n",
       "      <td>WITH locations AS\\n  (SELECT *\\n   FROM {{ ref...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>other</td>\n",
       "      <td>locations</td>\n",
       "      <td>{'semantic_models': [{'name': 'locations', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['stg_locations']</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>Retrieves all location records from the 'stg_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Code:\\n        WITH locations AS\\n  (SELECT *\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   knowledge_type                           path            name extension  \\\n",
       "11         models      models/marts/products.sql    products.sql      .sql   \n",
       "3          models  models/staging/stg_orders.sql  stg_orders.sql      .sql   \n",
       "7          models     models/marts/locations.sql   locations.sql      .sql   \n",
       "\n",
       "                                                 code config materialized  \\\n",
       "11  WITH products AS\\n  (SELECT *\\n   FROM {{ ref(...    NaN          NaN   \n",
       "3   WITH SOURCE AS\\n  (SELECT *\\n   FROM {{ source...    NaN          NaN   \n",
       "7   WITH locations AS\\n  (SELECT *\\n   FROM {{ ref...    NaN          NaN   \n",
       "\n",
       "   is_snapshot has_jinja_code model_category   vertical  \\\n",
       "11       False          False          other   products   \n",
       "3        False          False            stg     orders   \n",
       "7        False          False          other  locations   \n",
       "\n",
       "                                             yml_code  \\\n",
       "11  {'semantic_models': [{'name': 'products', 'des...   \n",
       "3   {'models': [{'name': 'stg_orders', 'descriptio...   \n",
       "7   {'semantic_models': [{'name': 'locations', 'de...   \n",
       "\n",
       "                                                tests has_tests  \\\n",
       "11                                                NaN     False   \n",
       "3   {'columns': {'order_id': ['not_null', 'unique'...      True   \n",
       "7                                                 NaN     False   \n",
       "\n",
       "                                              sql_ids  \\\n",
       "11                                                NaN   \n",
       "3   ['location_id', 'store_id', 'customer_id', 'or...   \n",
       "7                                                 NaN   \n",
       "\n",
       "   has_select_all_in_last_select has_group_by primary_key filters is_filtered  \\\n",
       "11                          True        False         NaN     NaN       False   \n",
       "3                           True        False    order_id     NaN       False   \n",
       "7                           True        False         NaN     NaN       False   \n",
       "\n",
       "                                    macros has_macros      parent_models  \\\n",
       "11                                     NaN      False   ['stg_products']   \n",
       "3   ['cents_to_dollars', 'dbt.date_trunc']       True                 []   \n",
       "7                                      NaN      False  ['stg_locations']   \n",
       "\n",
       "   is_source_model               source            children_models  \\\n",
       "11           False                  NaN                         []   \n",
       "3             True  ['ecom.raw_orders']  ['order_items', 'orders']   \n",
       "7            False                  NaN                         []   \n",
       "\n",
       "   is_end_model                                  model_description  \\\n",
       "11         True  Retrieves all product records from the 'stg_pr...   \n",
       "3         False  Retrieves order data from the 'ecom.raw_orders...   \n",
       "7          True  Retrieves all location records from the 'stg_l...   \n",
       "\n",
       "   jinja_description packages is_macro is_seed description is_test  \\\n",
       "11               NaN     None     None    None        None    None   \n",
       "3                NaN     None     None    None        None    None   \n",
       "7                NaN     None     None    None        None    None   \n",
       "\n",
       "                                      contextual_info  \n",
       "11  Code:\\n        WITH products AS\\n  (SELECT *\\n...  \n",
       "3   Code:\\n        WITH SOURCE AS\\n  (SELECT *\\n  ...  \n",
       "7   Code:\\n        WITH locations AS\\n  (SELECT *\\...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbt_repo_knowledge_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def clean_metadata(documents):\n",
    "    cleaned_documents = []\n",
    "    for doc in documents:\n",
    "        cleaned_metadata = {\n",
    "            key: (\"\" if value is None else value) if isinstance(value, (str, int, float, bool, type(None))) else str(value)\n",
    "            for key, value in doc.metadata.items()\n",
    "        }\n",
    "        cleaned_documents.append(Document(page_content=doc.page_content, metadata=cleaned_metadata))\n",
    "    return cleaned_documents\n",
    "\n",
    "def save_vectorstore_to_chroma(documents, embeddings, persist_directory=CHROMADB_DIRECTORY):\n",
    "    vectorstore = Chroma.from_documents(documents, embeddings, persist_directory=persist_directory)\n",
    "    print(f\"Vectorstore saved to {persist_directory}\")\n",
    "    return persist_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore saved to ../chromadb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../chromadb'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "cleaned_documents = clean_metadata(documents)\n",
    "save_vectorstore_to_chroma(cleaned_documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_chroma.vectorstores.Chroma object at 0x1395f8e50>\n"
     ]
    }
   ],
   "source": [
    "loaded_vectorstore = Chroma(persist_directory=CHROMADB_DIRECTORY)\n",
    "print(loaded_vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_dbt_lineage(dbt_repo_knowledge_df):\n",
    "    # Generate lineage df\n",
    "    lineage_df = dbt_repo_knowledge_df[(dbt_repo_knowledge_df['knowledge_type'] == 'models') & (dbt_repo_knowledge_df['extension'] == '.sql')][['name','parent_models','children_models','source']]\n",
    "    lineage_df['model_name'] = lineage_df['name'].apply(lambda x: x[:-4])\n",
    "    lineage_df = lineage_df.drop(columns=['name'])[['model_name','source','parent_models','children_models']]\n",
    "\n",
    "    # Ensure valid lists in columns\n",
    "    lineage_df[\"source\"] = lineage_df[\"source\"].apply(lambda x: x if isinstance(x, list) else eval(x) if isinstance(x, str) and x.startswith('[') else [])\n",
    "    lineage_df[\"parent_models\"] = lineage_df[\"parent_models\"].apply(lambda x: x if isinstance(x, list) else eval(x) if isinstance(x, str) and x.startswith('[') else [])\n",
    "    lineage_df[\"children_models\"] = lineage_df[\"children_models\"].apply(lambda x: x if isinstance(x, list) else eval(x) if isinstance(x, str) and x.startswith('[') else [])\n",
    "\n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add source nodes\n",
    "    all_sources = lineage_df[\"source\"].sum()\n",
    "    unique_sources = list(set(all_sources))\n",
    "    G.add_nodes_from(unique_sources, layer=0)\n",
    "\n",
    "    # Add nodes and edges for models\n",
    "    for _, row in lineage_df.iterrows():\n",
    "        layer = 1 if row[\"source\"] and not row[\"parent_models\"] else 2 if row[\"source\"] and row[\"parent_models\"] else 3 if not row[\"source\"] and row[\"parent_models\"] and row[\"children_models\"] else 4 if not row[\"children_models\"] and row[\"parent_models\"] else None\n",
    "        if layer:\n",
    "            G.add_node(row[\"model_name\"], layer=layer)\n",
    "            for source in row[\"source\"]:\n",
    "                G.add_edge(source, row[\"model_name\"])\n",
    "            for parent in row[\"parent_models\"]:\n",
    "                G.add_edge(parent, row[\"model_name\"])\n",
    "            for child in row[\"children_models\"]:\n",
    "                G.add_edge(row[\"model_name\"], child)\n",
    "\n",
    "    # Assign colors based on model type\n",
    "    def get_color(node):\n",
    "        if node in unique_sources:\n",
    "            return \"lightgreen\"\n",
    "        elif G.out_degree(node) == 0:\n",
    "            return \"lightcoral\"\n",
    "        elif node.startswith(\"stg\"):\n",
    "            return \"lightblue\"\n",
    "        elif node.startswith(\"base\"):\n",
    "            return \"orange\"\n",
    "        elif node.startswith(\"int\"):\n",
    "            return \"pink\"\n",
    "        return \"gray\"\n",
    "\n",
    "    node_colors = [get_color(n) for n in G.nodes]\n",
    "\n",
    "    # Layout to minimize edge crossings\n",
    "    pos = nx.multipartite_layout(G, subset_key=\"layer\")\n",
    "\n",
    "    # Draw graph with rectangular nodes\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    nx.draw(\n",
    "        G, pos, with_labels=True, node_size=3000, font_size=10, font_weight=\"bold\",\n",
    "        arrowsize=20, node_color=node_colors, edgecolors=\"black\",\n",
    "    )\n",
    "    ax = plt.gca()\n",
    "    for node, (x, y) in pos.items():\n",
    "        ax.text(x, y, node, fontsize=10, ha=\"center\", va=\"center\",\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=get_color(node)))\n",
    "\n",
    "    plt.title(\"DBT Models Lineage\", fontsize=16)\n",
    "    plt.show()\n",
    "    return lineage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_df = plot_dbt_lineage(dbt_repo_knowledge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test simple Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "print(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA, LLMChain, SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "\n",
    "llm = ChatOpenAI(model=DEFAULT_LLM_MODEL, temperature=0.1, openai_api_key=OPENAI_API_KEY, openai_organization = OPENAI_ORGANIZATION)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are a dbt expert. Based on the following context, answer the question concisely and accurately:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\"\"\"\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Que modelos se veran fectados si cambio el nombre de customer_id en stg_customers\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(result[\"result\"])\n",
    "print(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Tool\n",
    "retrieval_tool = Tool(\n",
    "    name=\"Retrieve Info\",\n",
    "    func=lambda query: retriever.get_relevant_documents(query),\n",
    "    description=\"Retrieve relevant context from the knowledge base.\",\n",
    ")\n",
    "\n",
    "# Task Execution Prompt\n",
    "task_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "        You are a dbt expert. Based on the context provided, perform the task below step-by-step:\n",
    "        \n",
    "        Task: {question}\n",
    "        Context: {context}\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "# QA Chain for Task Execution\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": task_prompt},\n",
    ")\n",
    "\n",
    "# Task Execution Tool\n",
    "task_tool = Tool(\n",
    "    name=\"DBT Task Executor\",\n",
    "    func=lambda query: qa_chain.invoke({\"query\": query}),\n",
    "    description=\"Execute dbt-related tasks like adding columns, creating models, or verifying dependencies.\",\n",
    ")\n",
    "\n",
    "# Agent Configuration\n",
    "tools = [retrieval_tool, task_tool]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Query\n",
    "query = \"Add a new column 'customer_age' to the 'stg_customers' model. The new column is available in the customer sources\"\n",
    "\n",
    "# Run the Agent\n",
    "result = agent.run(query)\n",
    "print(\"Agent Output:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start complete chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=DEFAULT_LLM_MODEL, temperature=0.1, openai_api_key=OPENAI_API_KEY, openai_organization = OPENAI_ORGANIZATION)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_upstream(lineage_df, model_name):\n",
    "    visited = set()\n",
    "    frontier = [model_name]\n",
    "    while frontier:\n",
    "        current = frontier.pop()\n",
    "        row = lineage_df[lineage_df[\"model_name\"] == current]\n",
    "        if not row.empty:\n",
    "            for source in row[\"source\"].iloc[0]:\n",
    "                if source not in visited:\n",
    "                    visited.add(source)\n",
    "                    frontier.append(source)\n",
    "            for parent in row[\"parent_models\"].iloc[0]:\n",
    "                if parent not in visited:\n",
    "                    visited.add(parent)\n",
    "                    frontier.append(parent)\n",
    "    return sorted(visited)\n",
    "\n",
    "def gather_downstream(lineage_df, model_name):\n",
    "    visited = set()\n",
    "    frontier = [model_name]\n",
    "    while frontier:\n",
    "        current = frontier.pop()\n",
    "        row = lineage_df[lineage_df[\"model_name\"] == current]\n",
    "        if not row.empty:\n",
    "            for child in row[\"children_models\"].iloc[0]:\n",
    "                if child not in visited:\n",
    "                    visited.add(child)\n",
    "                    frontier.append(child)\n",
    "    return sorted(visited)\n",
    "\n",
    "def get_affected_models(lineage_df, model_name):\n",
    "    up = gather_upstream(lineage_df, model_name)\n",
    "    down = gather_downstream(lineage_df, model_name)\n",
    "    return {\n",
    "        \"upstream\": list(up),\n",
    "        \"downstream\": list(down),\n",
    "    }\n",
    "\n",
    "get_affected_models(lineage_df, 'order_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class Step:\n",
    "    \"\"\"Base class for a step in the processing pipeline.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def execute(self, input_data, context):\n",
    "        raise NotImplementedError(\"Each step must implement the execute method.\")\n",
    "\n",
    "class InterpretationStep(Step):\n",
    "    \"\"\"Evaluate the user's request and decide the type of action needed.\"\"\"\n",
    "    def __init__(self, llm):\n",
    "        super().__init__(\"Interpretation\")\n",
    "        self.llm = llm\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"request\"],\n",
    "            template=(\"\"\"\n",
    "                <<>ROLE>>>\n",
    "                You are an expert in interpreting user requests and translating them into clear and concise decisions and actions, based on your deep expertise as an Analytics Engineer, knowledge of dbt and in interpreting and translating problems into solutions.      \n",
    "\n",
    "                <<<TASK>>>      \n",
    "                Evaluate the request: {request}\n",
    "                --------------------\n",
    "                and based on the evaluation, determine the required action:\n",
    "                1) adding a field -> return ADD_COLUMN\n",
    "                2) modifying an existing model -> return MODIFY_MODEL\n",
    "                3) retrieving and returning specific information. -> return RETRIVE_INFO\n",
    "                \n",
    "                Reflect on the request and provide a concise plan for the approach:\n",
    "                - If the action involves adding a field: Identify where the field is currently available, if provided.\n",
    "                - Determine how to propagate the field through the necessary models or transformations to integrate it into the target model.\n",
    "                - Consider the impact on related models and dependencies.\n",
    "                - If the action involves modifying an existing model: Identify the specific changes required.\n",
    "                - Assess how these changes affect the structure, relationships, and downstream dependencies of the model.\n",
    "                - If the action involves retrieving or returning information: Identify the models containing the relevant data.\n",
    "                - Analyze how these models are related, and determine the queries or transformations needed to extract the requested information.\n",
    "                      \n",
    "                <<<OUPUT>>>\n",
    "                Return the required action from the three proposed, and a short explanaition of the required work.\n",
    "                REMEMBER: Provide no extra commentary or explanation, just the minimal information required,  \n",
    "                return only useful information, no additional filler text or unnecessary explanations, get to the point.\n",
    "            \"\"\")   \n",
    "        )\n",
    "\n",
    "    def execute(self, input_data, context):\n",
    "        print(f\"Step: {self.name} | Input: {input_data}\")\n",
    "        prompt = self.prompt_template.format(request=input_data)\n",
    "        interpretation = self.llm.invoke(prompt)\n",
    "        context[\"interpretation\"] = interpretation\n",
    "        print(f\"Step: {self.name} | Output: {interpretation}\")\n",
    "        return interpretation\n",
    "\n",
    "class EvaluationStep(Step):\n",
    "    \"\"\"Evaluates on the user's request based on evaluation.\"\"\"\n",
    "    def __init__(self, llm):\n",
    "        super().__init__(\"Evaluation\")\n",
    "        self.llm = llm\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"request\", \"interpretation\"],\n",
    "            template=(\"\"\"\n",
    "                <<>ROLE>>>\n",
    "                You are an expert in evaluating user requests and translating them into clear and concise decisions and actions, based on your deep expertise as an Analytics Engineer, knowledge of dbt and in interpreting and translating requests into solutions.      \n",
    "\n",
    "                <<<TASK>>>      \n",
    "                Based on the interpretation of an expert dbt and problem interpreter: {interpretation}\n",
    "                --------------------\n",
    "                of the original request\n",
    "                ORIGINAL REQUEST: {request}\n",
    "                --------------------\n",
    "                Include only these topics if relevant:\n",
    "                - Target models or files\n",
    "                - Field existence\n",
    "                - Documentation needs\n",
    "                - Dependencies and relationships\n",
    "                - Performance/design considerations\n",
    "                - Tests\n",
    "                - dbt project config\n",
    "                - Code or logic generation\n",
    "                \n",
    "                Summarize only the necessary actions, no filler. Think about all the considerations and steps required to handle this request effectively.\n",
    "                Your evaluation could include the following actions:\n",
    "                - Identify the target model or models: Analyze the dependency tree to locate the model where the change should occur.\n",
    "                - Understand its upstream sources (seeds, sources or base models)\n",
    "                - Understand downstream dependencies of the model.\n",
    "                - Documentation: Assess if it's going to be necessary to add adjustments to the documentation, and which would be this changes.\n",
    "                - Unique keys and IDs: Examine the available unique keys and identifiers in the initial, intermediate, and final models.\n",
    "                - Decide how these can be used to integrate the field or establish relationships between models.\n",
    "                - Check if the granularity of the model can be altered through the changes added.\n",
    "                - Evaluate performance and design: Review the data pipeline from start to finish.\n",
    "                - Decide where the change or addition would be most optimal in terms of performance, data modeling, and maintainability.\n",
    "                - Project state and impact: Consider the current state of the dbt project and how the changes might affect the broader model chain.\n",
    "                - Macros and seeds: Check if relevant macros or seed data exist that can help transform or derive the required field or model.\n",
    "                - Tests: Identify existing tests for the field or model and determine whether new tests need to be added or adjusted to validate the changes.\n",
    "                - dbt project configuration: Review the general configuration (e.g., variables, environments, conventions) in the dbt_project.yml file to ensure the changes align with project standards and won't disrupt the schema.\n",
    "                - Code generation: fragments of SQL logic needed, including CTEs or columns.\n",
    "                - Evaluate whether an intermediate model is necessary or if the logic can be handled within the existing pipeline.\n",
    "                - Documentation generation: Specify the documentation needed for any fields, models, or logic added or updated as part of this request. Only the things to add or change.\n",
    "                \n",
    "                <<<OUPUT>>>\n",
    "                Provide a concise summary of the high-level tasks based on your analysis, with the reflection of each one of them to be prepared to completed in the next steps when context is provided. If you don't have the info to perform the action because it's necessary context of the project, code or the lineage of the models, don't answer it, in next steps context will be provide as input to answer it properly. Mark it as it's necessart the context to responde it, and only do the reflection part using your logic as dbt expert.\n",
    "                No extra checks or steps that are not on this list, select only the needed actions for the request.\n",
    "                Return only useful information, no additional filler text or unnecessary explanations, get to the point.\n",
    "                      \n",
    "                REMEMBER: Provide no extra commentary or explanation, just the minimal information required.\n",
    "            \"\"\")\n",
    "        )\n",
    "\n",
    "    def execute(self, input_data, context):\n",
    "        print(f\"Step: {self.name} | Input: {input_data}\")\n",
    "        interpretation = context.get(\"interpretation\", \"\")\n",
    "        prompt = self.prompt_template.format(request=input_data, interpretation=interpretation)\n",
    "        evaluation = self.llm.invoke(prompt)\n",
    "        context[\"evaluation\"] = evaluation\n",
    "        print(f\"Step: {self.name} | Output: {evaluation}\")\n",
    "        return evaluation\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class LineageResponse(BaseModel):\n",
    "    model: str\n",
    "    scope: Literal['UP', 'DOWN', 'ALL']\n",
    "\n",
    "class LineageStep(Step):\n",
    "    \"\"\"Identify which models or documents should be consulted or modified using dbt lineage.\"\"\"\n",
    "    def __init__(self, llm, vectorstore):\n",
    "        super().__init__(\"Lineage\")\n",
    "        self.llm = llm\n",
    "        self.vectorstore = vectorstore\n",
    "        self.parser = PydanticOutputParser(pydantic_object=LineageResponse)\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"evaluation\", \"retrieved_context\"],\n",
    "            template=(\"\"\"\n",
    "                <<>ROLE>>>\n",
    "                You are an expert in identifying the models and changes needed in a dbt repo given a request, based on your deep expertise as an Analytics Engineer, knowledge of dbt and in interpreting and translating requests into solutions, and using context and context information from the repository code and other models.\n",
    "\n",
    "                <<<TASK>>>      \n",
    "                Based on this evaluation: {evaluation}\n",
    "                --------------------\n",
    "                and the retrieved context, remember the meaning of all the context data:\n",
    "                CONTEXT INFO AND METADATA MEANING:\n",
    "                - knowledge_type: Specifies whether the resource is about files within the dbt project configuration, or data models used in the pipeline.\n",
    "                - name: Name of the file.\n",
    "                - path: Path within the repository where the file or resource is located, relative to the project root.\n",
    "                - source: The original dataset, from which the model or resource pulls its data. Only for the first layer of the model.\n",
    "                - parents: dbt models  that serve as input dependencies for the current model or file.\n",
    "                - children: dbt models that depend on this resource as an input for their logic or data processing.\n",
    "                - config: Configuration parameters defined in the file, specifying behaviors, sort keys, materialization...\n",
    "                - materialized: Indicates how the data model is materialized (e.g., as a table, view, or ephemeral model) in the pipeline.\n",
    "                - is_snapshot: Boolean flag that identifies whether the file represents a snapshot dbt model.\n",
    "                - model_category: The logical dbt categorization of the model inside the project, such as base, staging, intermediate, marts...\n",
    "                - vertical: Business domain or vertical to which the resource belongs, such as e-commerce, finance, supply...\n",
    "                - has_tests: Boolean flag indicating if there are tests associated with this resource in the model .yaml file or in the tests folder.\n",
    "                - has_select_all_in_last_select: Specifies if the final SQL query in the file uses a SELECT * statement. So all columns of previous CTEs will be consider as output of the model.\n",
    "                - has_group_by: Boolean flag indicating if the SQL code includes a GROUP BY clause for aggregating data.\n",
    "                - is_filtered: Boolean flag that specifies whether the resource applies filters to its data with WHERE, HAVING, JOIN...\n",
    "                - is_source_model: The model uses the source macro to extract the data from the dbt project sources. It belongs to the first layer of all dbt models.\n",
    "                - is_seed: Specifies if the resource is a seed file.\n",
    "                - is_end_model: Boolean flag identifying if this is a terminal model in the data pipeline, representing the final output.\n",
    "                - is_macro: Boolean flag indicating if the file defines a macro, used for reusable logic across the project. It does not count macros ref to call other models or source to connect to sources.\n",
    "                - is_test: Indicates whether the file is a test sql definition used for testing purposes of other dbt models.\n",
    "                - macros: Name of the macros used in the dbt model if any. It does not count macros ref to call other models or source to connect to sources.\n",
    "                - packages: List of external packages or dependencies required for the resource or project functionality. Only not None in the packages.yml\trow.\n",
    "\n",
    "                      \n",
    "                RETRIEVED CONTEXT: {retrieved_context}\n",
    "                --------------------\n",
    "                Determine:\n",
    "                - The primary dbt model directly affected (e.g., where a field is added, a modification is made, or information is requested).\n",
    "                - Whether upstream models (UP), downstream models (DOWN), or both (ALL) are necessary to handle this request correctly.\n",
    "                \n",
    "                Consider the following cases:\n",
    "                1. If a new field is added, specify the model where the field will be added and indicate UP for upstream models needed to populate the field.\n",
    "                2. If an existing field is modified, specify the model where the change occurs and indicate DOWN for downstream models affected by the change.\n",
    "                3. If information is requested, specify the model containing the requested information and indicate UP, DOWN, or ALL based on the context of the data needed.\n",
    "                4. If a field or model is removed, specify the model being affected and indicate DOWN for downstream dependencies impacted.\n",
    "                      \n",
    "                <<<OUPUT>>>\n",
    "                Return the following json format: {{'model':model name, 'scope':UP/DOWN/ALL}}\n",
    "                REMEMBER: Provide no extra commentary or explanation, just the minimal information required.\n",
    "            \"\"\")\n",
    "        )\n",
    "\n",
    "    def execute(self, input_data, context):\n",
    "        print(f\"Step: {self.name} | Input: {input_data}\")\n",
    "        evaluation = context.get(\"evaluation\", \"\")\n",
    "\n",
    "        documents = self.vectorstore.as_retriever().invoke(input_data)\n",
    "        retrieved_context = \"\\n\".join([doc.page_content for doc in documents if hasattr(doc, 'page_content')])\n",
    "        context[\"documents\"] = documents\n",
    "        print(f\"Step: {self.name} | Retrieved Context: {retrieved_context}\")\n",
    "\n",
    "        prompt = self.prompt_template.format(evaluation=evaluation, retrieved_context=retrieved_context)\n",
    "\n",
    "        response = self.llm.invoke(prompt)\n",
    "        context[\"lineage_analysis\"] = response.dict()\n",
    "        print(f\"Step: {self.name} | Output: {response}\")\n",
    "\n",
    "        # ADD DOC FILTERING\n",
    "        lineage_analysis_raw = response.dict()\n",
    "        content = lineage_analysis_raw.get(\"content\", \"\")\n",
    "\n",
    "        json_string = content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        lineage_analysis = eval(json_string)  # Use eval cautiously; use json.loads if the string is valid JSON\n",
    "        print(lineage_analysis)\n",
    "        model_name = lineage_analysis.get(\"model\")\n",
    "        scope = lineage_analysis.get(\"scope\", \"\").upper()\n",
    "\n",
    "        affected_models = get_affected_models(lineage_df, model_name)\n",
    "        if scope == \"UP\":\n",
    "            filtered_models = affected_models[\"upstream\"]\n",
    "        elif scope == \"DOWN\":\n",
    "            filtered_models = affected_models[\"downstream\"]\n",
    "        elif scope == \"ALL\":\n",
    "            filtered_models = affected_models[\"upstream\"] + affected_models[\"downstream\"]\n",
    "\n",
    "        filtered_models = list(set(filtered_models + [model_name]))\n",
    "\n",
    "        filtered_documents = [\n",
    "            doc for doc in documents\n",
    "            if hasattr(doc, 'metadata') and doc.metadata.get(\"name\") in filtered_models\n",
    "        ]\n",
    "        print(f\"Step: {self.name} | Filtered Documents: {len(filtered_documents)}\")\n",
    "\n",
    "        # Create a new vectorstore with the filtered documents\n",
    "        new_vectorstore = Chroma.from_documents(filtered_documents, self.vectorstore.embedding_function)\n",
    "\n",
    "        # Return the response and the new retriever\n",
    "        new_retriever = new_vectorstore.as_retriever()\n",
    "        return response, new_retriever\n",
    "\n",
    "class PlanStep(Step):\n",
    "    \"\"\"Plan the steps needed based on evaluation and retrieved context.\"\"\"\n",
    "    def __init__(self, llm):\n",
    "        super().__init__(\"Plan\")\n",
    "        self.llm = llm\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"evaluation\", \"retrieved_context\", \"lineage_analysis\"],\n",
    "            template=(\"\"\"\n",
    "                <<>ROLE>>>\n",
    "                You are an expert in planning and deciding the necessary changes in the affected models of a dbt project given a request, based on your deep expertise as an Analytics Engineer, knowledge of dbt and in interpreting and translating requests into solutions, and using context and context information from the repository code and other models.      \n",
    "\n",
    "                <<<TASK>>>      \n",
    "                Based on this evaluation: {evaluation}\n",
    "                --------------------\n",
    "                and the retrieved context, remember the meaning of all the context data:\n",
    "                CONTEXT INFO AND METADATA MEANING:\n",
    "                - knowledge_type: Specifies whether the resource is about files within the dbt project configuration, or data models used in the pipeline.\n",
    "                - name: Name of the file.\n",
    "                - path: Path within the repository where the file or resource is located, relative to the project root.\n",
    "                - source: The original dataset, from which the model or resource pulls its data. Only for the first layer of the model.\n",
    "                - parents: dbt models  that serve as input dependencies for the current model or file.\n",
    "                - children: dbt models that depend on this resource as an input for their logic or data processing.\n",
    "                - config: Configuration parameters defined in the file, specifying behaviors, sort keys, materialization...\n",
    "                - materialized: Indicates how the data model is materialized (e.g., as a table, view, or ephemeral model) in the pipeline.\n",
    "                - is_snapshot: Boolean flag that identifies whether the file represents a snapshot dbt model.\n",
    "                - model_category: The logical dbt categorization of the model inside the project, such as base, staging, intermediate, marts...\n",
    "                - vertical: Business domain or vertical to which the resource belongs, such as e-commerce, finance, supply...\n",
    "                - has_tests: Boolean flag indicating if there are tests associated with this resource in the model .yaml file or in the tests folder.\n",
    "                - has_select_all_in_last_select: Specifies if the final SQL query in the file uses a SELECT * statement. So all columns of previous CTEs will be consider as output of the model.\n",
    "                - has_group_by: Boolean flag indicating if the SQL code includes a GROUP BY clause for aggregating data.\n",
    "                - is_filtered: Boolean flag that specifies whether the resource applies filters to its data with WHERE, HAVING, JOIN...\n",
    "                - is_source_model: The model uses the source macro to extract the data from the dbt project sources. It belongs to the first layer of all dbt models.\n",
    "                - is_seed: Specifies if the resource is a seed file.\n",
    "                - is_end_model: Boolean flag identifying if this is a terminal model in the data pipeline, representing the final output.\n",
    "                - is_macro: Boolean flag indicating if the file defines a macro, used for reusable logic across the project. It does not count macros ref to call other models or source to connect to sources.\n",
    "                - is_test: Indicates whether the file is a test sql definition used for testing purposes of other dbt models.\n",
    "                - macros: Name of the macros used in the dbt model if any. It does not count macros ref to call other models or source to connect to sources.\n",
    "                - packages: List of external packages or dependencies required for the resource or project functionality. Only not None in the packages.yml\trow.\n",
    "\n",
    "                RETRIEVED CONTEXT: {retrieved_context}\n",
    "                --------------------\n",
    "                Create a detailed step-by-step plan of the changes required in the existing models or files within the repository.\n",
    "                To implement the requested change accurately.\n",
    "                1. Ensure that you only refer to files, models, or fields that are explicitly mentioned in the retrieved information.\n",
    "                2. Do not invent new models, fields, or dependencies. \n",
    "                3. Focus on:\n",
    "                  - Identifying the exact files or models that need modifications, based on the retrieved context.\n",
    "                  - Specifying what changes should be made, such as adding fields, updating logic, or modifying relationships.\n",
    "                  - Highlighting any dependencies between models or files and describing how these should be handled.\n",
    "                  - Extract children or parent models affected.\n",
    "                  - If code fragments are provided in the retrieved context, incorporate them where applicable and explain their role.\n",
    "                  - If no specific code or file is mentioned in the retrieved information, state that no changes should be made to existing files.\n",
    "                  - Ensure the changes align with the dbt project's standards, such as conventions in `dbt_project.yml`, and do not introduce schema-breaking modifications.\n",
    "                \n",
    "                4. No extra checks or steps that are not on this list.\n",
    "                5. Provide precise and actionable recommendations, avoiding any assumptions beyond the retrieved information.\n",
    "                      \n",
    "                <<<OUPUT>>>\n",
    "                Return a summary of all the process, with the reflection, plan and context and the changes tht are neeeded to perfor\n",
    "                      - The original request.\n",
    "                      - The interpretarion of the request.\n",
    "                      - The affected models with the info of the context and the lineage.\n",
    "                      - All the necceasry changes step by step with a clear and short explanaiton of why is needed.\n",
    "                Return only useful information, no additional filler text or unnecessary explanations, get to the point.\n",
    "                REMEMBER: Provide no extra commentary or explanation, just the minimal information required.\n",
    "            \"\"\")\n",
    "        )\n",
    "\n",
    "    def execute(self, input_data, context):\n",
    "        print(f\"Step: {self.name} | Input: {input_data}\")\n",
    "        evaluation = context.get(\"evaluation\", \"\")\n",
    "        retriever = context.get(\"filtered_retriever\")\n",
    "\n",
    "        documents = retriever.invoke(input_data)\n",
    "        retrieved_context = \"\\n\".join([doc.page_content for doc in documents if hasattr(doc, 'page_content')])\n",
    "        context[\"documents\"] = documents\n",
    "        print(f\"Step: {self.name} | Retrieved Context: {retrieved_context}\")\n",
    "\n",
    "        prompt = self.prompt_template.format(evaluation=evaluation, retrieved_context=retrieved_context)\n",
    "\n",
    "        plan = self.llm.invoke(prompt)\n",
    "        context[\"plan\"] = plan\n",
    "        print(f\"Step: {self.name} | Output: {plan}\")\n",
    "        return plan\n",
    "\n",
    "class ChatPipeline:\n",
    "    \"\"\"Manages the pipeline of steps.\"\"\"\n",
    "    def __init__(self, steps):\n",
    "        self.steps = steps\n",
    "\n",
    "    def execute(self, input_data):\n",
    "        context = {}\n",
    "        for step in self.steps:\n",
    "            print(f\"\\nExecuting step: {step.name}\")\n",
    "            result = step.execute(input_data, context)\n",
    "            if isinstance(result, tuple) and len(result) == 2:\n",
    "                response, filtered_retriever = result\n",
    "                context[\"filtered_retriever\"] = filtered_retriever\n",
    "            else:\n",
    "                response = result\n",
    "\n",
    "            print(f\"Finished step: {step.name} | Result: {response}\\n\")\n",
    "        return context\n",
    "\n",
    "def main(user_input, llm, retriever):\n",
    "    # Define the steps\n",
    "    steps = [\n",
    "        InterpretationStep(llm),\n",
    "        EvaluationStep(llm),\n",
    "        LineageStep(llm, vectorstore),\n",
    "        PlanStep(llm),\n",
    "    ]\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = ChatPipeline(steps)\n",
    "\n",
    "    context = pipeline.execute(user_input)\n",
    "    print(\"Context at the end of pipeline:\", context)\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing step: Interpretation\n",
      "Step: Interpretation | Input: si cambio algo en el modelo de salida orders, cuales son todos sus parent models que tendria que consultar\n",
      "Step: Interpretation | Output: content='RETRIVE_INFO: You need to identify all parent models related to the output model \"orders\" to understand the dependencies and potential impacts of any changes made.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 359, 'total_tokens': 392, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None} id='run-07342a4e-fa46-472b-ad63-fc2a460c8203-0' usage_metadata={'input_tokens': 359, 'output_tokens': 33, 'total_tokens': 392, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Finished step: Interpretation | Result: content='RETRIVE_INFO: You need to identify all parent models related to the output model \"orders\" to understand the dependencies and potential impacts of any changes made.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 359, 'total_tokens': 392, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None} id='run-07342a4e-fa46-472b-ad63-fc2a460c8203-0' usage_metadata={'input_tokens': 359, 'output_tokens': 33, 'total_tokens': 392, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "\n",
      "Executing step: Evaluation\n",
      "Step: Evaluation | Input: si cambio algo en el modelo de salida orders, cuales son todos sus parent models que tendria que consultar\n",
      "Step: Evaluation | Output: content='1. **Identify Target Model**: Analyze the dependency tree to locate the \"orders\" model.\\n\\n2. **Understand Upstream Sources**: Identify all parent models that feed into \"orders\" (seeds, sources, or base models).\\n\\n3. **Understand Downstream Dependencies**: Assess how changes to \"orders\" may impact downstream models.\\n\\n4. **Documentation Needs**: Determine if documentation updates are necessary for the \"orders\" model and its parent models.\\n\\n5. **Unique Keys and IDs**: Review unique keys and identifiers in the \"orders\" model and its parents for potential integration.\\n\\n6. **Granularity Check**: Evaluate if the granularity of the \"orders\" model can be altered based on changes.\\n\\n7. **Performance and Design Evaluation**: Review the data pipeline for optimal placement of changes regarding performance and maintainability.\\n\\n8. **Project State and Impact**: Consider the current state of the dbt project and potential impacts of changes on the model chain.\\n\\n9. **Macros and Seeds**: Check for relevant macros or seed data that could assist in transforming or deriving fields for \"orders.\"\\n\\n10. **Tests**: Identify existing tests for \"orders\" and determine if new tests are needed to validate changes.\\n\\n11. **dbt Project Configuration**: Review dbt_project.yml for alignment with project standards regarding the proposed changes.\\n\\n12. **Code Generation**: Prepare SQL logic fragments needed for changes, including CTEs or columns.\\n\\n13. **Intermediate Model Evaluation**: Decide if an intermediate model is necessary for the changes or if they can be integrated into the existing pipeline.\\n\\n14. **Documentation Generation**: Specify any documentation updates needed for fields, models, or logic related to \"orders.\" \\n\\n*Note: Context is necessary to perform specific actions effectively.*' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 363, 'prompt_tokens': 1010, 'total_tokens': 1373, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None} id='run-52b7f4ae-4029-4403-bdb7-1b17572eea1d-0' usage_metadata={'input_tokens': 1010, 'output_tokens': 363, 'total_tokens': 1373, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Finished step: Evaluation | Result: content='1. **Identify Target Model**: Analyze the dependency tree to locate the \"orders\" model.\\n\\n2. **Understand Upstream Sources**: Identify all parent models that feed into \"orders\" (seeds, sources, or base models).\\n\\n3. **Understand Downstream Dependencies**: Assess how changes to \"orders\" may impact downstream models.\\n\\n4. **Documentation Needs**: Determine if documentation updates are necessary for the \"orders\" model and its parent models.\\n\\n5. **Unique Keys and IDs**: Review unique keys and identifiers in the \"orders\" model and its parents for potential integration.\\n\\n6. **Granularity Check**: Evaluate if the granularity of the \"orders\" model can be altered based on changes.\\n\\n7. **Performance and Design Evaluation**: Review the data pipeline for optimal placement of changes regarding performance and maintainability.\\n\\n8. **Project State and Impact**: Consider the current state of the dbt project and potential impacts of changes on the model chain.\\n\\n9. **Macros and Seeds**: Check for relevant macros or seed data that could assist in transforming or deriving fields for \"orders.\"\\n\\n10. **Tests**: Identify existing tests for \"orders\" and determine if new tests are needed to validate changes.\\n\\n11. **dbt Project Configuration**: Review dbt_project.yml for alignment with project standards regarding the proposed changes.\\n\\n12. **Code Generation**: Prepare SQL logic fragments needed for changes, including CTEs or columns.\\n\\n13. **Intermediate Model Evaluation**: Decide if an intermediate model is necessary for the changes or if they can be integrated into the existing pipeline.\\n\\n14. **Documentation Generation**: Specify any documentation updates needed for fields, models, or logic related to \"orders.\" \\n\\n*Note: Context is necessary to perform specific actions effectively.*' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 363, 'prompt_tokens': 1010, 'total_tokens': 1373, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None} id='run-52b7f4ae-4029-4403-bdb7-1b17572eea1d-0' usage_metadata={'input_tokens': 1010, 'output_tokens': 363, 'total_tokens': 1373, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "\n",
      "Executing step: Lineage\n",
      "Step: Lineage | Input: si cambio algo en el modelo de salida orders, cuales son todos sus parent models que tendria que consultar\n",
      "Step: Lineage | Retrieved Context: Code:\n",
      "                                          id                             customer          ordered_at                             store_id  subtotal  tax_paid  order_total\n",
      "9bed808a-5074-4dfb-b1eb-388e2e60a6da 50a2d1c4-d788-4498-a6f7-dd75d4db588f 2016-09-01T15:01:00 4b6c2304-2b9e-41e4-942a-cf11a1819378       700        42          742\n",
      "b83630c1-0fdc-4cd2-818d-0b6d4384ce86 438005c2-dd1d-48aa-8bfd-7fb06851b5f8 2016-09-01T10:39:00 4b6c2304-2b9e-41e4-942a-cf11a1819378       700        42          742\n",
      "3b4a03db-7b23-4673-a88a-7f51b01ca497 5261268c-aa94-438a-921a-05efc0d414ac 2016-09-01T07:46:00 4b6c2304-2b9e-41e4-942a-cf11a1819378       700        42          742\n",
      "\n",
      "        Primary Key:\n",
      "        N/A\n",
      "\n",
      "        IDS:\n",
      "        N/A\n",
      "\n",
      "        Columns used to Filter the model throuhg JOINS, HAVING, WHERE...:\n",
      "        N/A\n",
      "\n",
      "        Tests:\n",
      "        N/A\n",
      "\n",
      "        YML Code:\n",
      "        N/A\n",
      "\n",
      "        Description for project files:\n",
      "        N/A\n",
      "\n",
      "        dbt Model description:\n",
      "        N/A\n",
      "\n",
      "        Jinja inside the dbt model description:\n",
      "        N/A\n",
      "Code:\n",
      "                                          id                             order_id     sku\n",
      "2e3cb58a-c73c-4216-9d70-66e91bb2ca32 9bed808a-5074-4dfb-b1eb-388e2e60a6da BEV-004\n",
      "0d005cee-30f1-4426-a786-833fcc77ae34 b83630c1-0fdc-4cd2-818d-0b6d4384ce86 BEV-004\n",
      "0b8661ef-9337-44cd-a12d-f2aa9badda01 3b4a03db-7b23-4673-a88a-7f51b01ca497 BEV-004\n",
      "\n",
      "        Primary Key:\n",
      "        N/A\n",
      "\n",
      "        IDS:\n",
      "        N/A\n",
      "\n",
      "        Columns used to Filter the model throuhg JOINS, HAVING, WHERE...:\n",
      "        N/A\n",
      "\n",
      "        Tests:\n",
      "        N/A\n",
      "\n",
      "        YML Code:\n",
      "        N/A\n",
      "\n",
      "        Description for project files:\n",
      "        N/A\n",
      "\n",
      "        dbt Model description:\n",
      "        N/A\n",
      "\n",
      "        Jinja inside the dbt model description:\n",
      "        N/A\n",
      "Code:\n",
      "        WITH SOURCE AS\n",
      "  (SELECT *\n",
      "   FROM {{ source('ecom', 'raw_orders') }}), renamed AS\n",
      "  (SELECT ----------  ids\n",
      " id AS order_id,\n",
      " store_id AS location_id,\n",
      " customer AS customer_id, ---------- numerics\n",
      " subtotal AS subtotal_cents,\n",
      " tax_paid AS tax_paid_cents,\n",
      " order_total AS order_total_cents, {{ cents_to_dollars('subtotal') }} AS subtotal, {{ cents_to_dollars('tax_paid') }} AS tax_paid, {{ cents_to_dollars('order_total') }} AS order_total, ---------- timestamps\n",
      " {{ dbt.date_trunc('day', 'ordered_at') }} AS ordered_at\n",
      "   FROM SOURCE)\n",
      "SELECT *\n",
      "FROM renamed\n",
      "\n",
      "        Primary Key:\n",
      "        order_id\n",
      "\n",
      "        IDS:\n",
      "        ['location_id', 'store_id', 'customer_id', 'order_id']\n",
      "\n",
      "        Columns used to Filter the model throuhg JOINS, HAVING, WHERE...:\n",
      "        N/A\n",
      "\n",
      "        Tests:\n",
      "        {'columns': {'order_id': ['not_null', 'unique']}, 'unit_tests': []}\n",
      "\n",
      "        YML Code:\n",
      "        {'models': [{'name': 'stg_orders', 'description': 'Order data with basic cleaning and transformation applied, one row per order.', 'data_tests': [{'dbt_utils.expression_is_true': {'expression': 'order_total - tax_paid = subtotal'}}], 'columns': [{'name': 'order_id', 'description': 'The unique key for each order.', 'data_tests': ['not_null', 'unique']}]}]}\n",
      "\n",
      "        Description for project files:\n",
      "        N/A\n",
      "\n",
      "        dbt Model description:\n",
      "        Retrieves order data from the 'ecom.raw_orders' source, applying basic cleaning and transformation. It renames fields, converts amounts from cents to dollars, and truncates the 'ordered_at' timestamp to the day. The model ensures that the order total minus tax equals the subtotal.\n",
      "\n",
      "        Jinja inside the dbt model description:\n",
      "        N/A\n",
      "Code:\n",
      "        packages:\n",
      "- package: dbt-labs/dbt_utils\n",
      "  version: 1.1.1\n",
      "- package: calogica/dbt_date\n",
      "  version: 0.10.0\n",
      "- git: https://github.com/dbt-labs/dbt-audit-helper.git\n",
      "  revision: 74072850a5bccd90235576d67530c98e3b7437f4\n",
      "sha1_hash: da0d5b1d5a48f6504805f6b1d5a0b2f9f233f34c\n",
      "\n",
      "\n",
      "        Primary Key:\n",
      "        N/A\n",
      "\n",
      "        IDS:\n",
      "        N/A\n",
      "\n",
      "        Columns used to Filter the model throuhg JOINS, HAVING, WHERE...:\n",
      "        N/A\n",
      "\n",
      "        Tests:\n",
      "        N/A\n",
      "\n",
      "        YML Code:\n",
      "        N/A\n",
      "\n",
      "        Description for project files:\n",
      "        N/A\n",
      "\n",
      "        dbt Model description:\n",
      "        N/A\n",
      "\n",
      "        Jinja inside the dbt model description:\n",
      "        N/A\n",
      "Step: Lineage | Output: content=\"```json\\n{'model': 'stg_orders', 'scope': 'ALL'}\\n```\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 2813, 'total_tokens': 2832, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None} id='run-3ad4cbef-f0c3-4984-bcad-a1f1a6fdb142-0' usage_metadata={'input_tokens': 2813, 'output_tokens': 19, 'total_tokens': 2832, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "{'model': 'stg_orders', 'scope': 'ALL'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hv/ckh3m6gn1sd45q2qctrqcwzh0000gn/T/ipykernel_76849/2018809332.py:199: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  context[\"lineage_analysis\"] = response.dict()\n",
      "/var/folders/hv/ckh3m6gn1sd45q2qctrqcwzh0000gn/T/ipykernel_76849/2018809332.py:203: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  lineage_analysis_raw = response.dict()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_affected_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msi cambio algo en el modelo de salida orders, cuales son todos sus parent models que tendria que consultar\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m loaded_vectorstore \u001b[38;5;241m=\u001b[39m Chroma(persist_directory\u001b[38;5;241m=\u001b[39mCHROMADB_DIRECTORY)\n\u001b[0;32m----> 3\u001b[0m llm_results \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_vectorstore\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 351\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(user_input, llm, retriever)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# Create the pipeline\u001b[39;00m\n\u001b[1;32m    349\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m ChatPipeline(steps)\n\u001b[0;32m--> 351\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext at the end of pipeline:\u001b[39m\u001b[38;5;124m\"\u001b[39m, context)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\n",
      "Cell \u001b[0;32mIn[41], line 329\u001b[0m, in \u001b[0;36mChatPipeline.execute\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExecuting step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    331\u001b[0m         response, filtered_retriever \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[41], line 212\u001b[0m, in \u001b[0;36mLineageStep.execute\u001b[0;34m(self, input_data, context)\u001b[0m\n\u001b[1;32m    209\u001b[0m model_name \u001b[38;5;241m=\u001b[39m lineage_analysis\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m scope \u001b[38;5;241m=\u001b[39m lineage_analysis\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscope\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m--> 212\u001b[0m affected_models \u001b[38;5;241m=\u001b[39m \u001b[43mget_affected_models\u001b[49m(lineage_df, model_name)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scope \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    214\u001b[0m     filtered_models \u001b[38;5;241m=\u001b[39m affected_models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupstream\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_affected_models' is not defined"
     ]
    }
   ],
   "source": [
    "user_input = \"si cambio algo en el modelo de salida orders, cuales son todos sus parent models que tendria que consultar\"\n",
    "loaded_vectorstore = Chroma(persist_directory=CHROMADB_DIRECTORY)\n",
    "llm_results = main(user_input, llm, loaded_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el contexto tiene que tener:\n",
    "USE RAG TO EXTRACT CONTEXT\n",
    "- los docs de los modelos filtrados tras procesar el lineage\n",
    "\n",
    "ALL\n",
    "- los tests o macros que esten en estos ultimos modelos, \n",
    "- el resto de ficheros de proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(llm_results['plan'].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
